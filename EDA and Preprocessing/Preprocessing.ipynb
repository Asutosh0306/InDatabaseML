{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QutaDLibHrd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load raw data (only finalized columns) -------------------------------\n",
    "dtypes = {'id':'int64', 'item_nbr':'int32', 'store_nbr':'int8', 'onpromotion':'str'}\n",
    "train = pd.read_csv('/content/drive/MyDrive/Dissertation/all files/train.csv',\n",
    "                    dtype=dtypes,\n",
    "                    parse_dates=['date'],\n",
    "                    usecols=['id','date','store_nbr','item_nbr','unit_sales','onpromotion'])\n",
    "\n",
    "stores = pd.read_csv('/content/drive/MyDrive/Dissertation/all files/stores.csv',\n",
    "                     usecols=['store_nbr','city','state','type','cluster'])\n",
    "\n",
    "items = pd.read_csv('/content/drive/MyDrive/Dissertation/all files/items.csv',\n",
    "                    usecols=['item_nbr','family','class','perishable'])\n",
    "\n",
    "hol = pd.read_csv('/content/drive/MyDrive/Dissertation/all files/holidays_events.csv',\n",
    "                  dtype={'transferred':'str'},\n",
    "                  parse_dates=['date'],\n",
    "                  usecols=['date','locale','locale_name','type','transferred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCuGdjehbTWQ"
   },
   "outputs": [],
   "source": [
    "# 2. Prepare holiday/event flags ------------------------------------------\n",
    "hol = (\n",
    "    hol[~hol.transferred.str.lower().eq('true')]      # drop transferred\n",
    "       .query(\"type!='Work Day'\")                     # drop compensatory work days\n",
    "       .assign(\n",
    "           on_hol=lambda df: df.type.map({\n",
    "               'Holiday':'Holiday','Bridge':'Holiday','Additional':'Holiday'\n",
    "           }),\n",
    "           on_evt=lambda df: df.type.map({'Event':'Event'})\n",
    "       )\n",
    ")\n",
    "locL = (\n",
    "    hol.query(\"locale=='Local'\")\n",
    "       .loc[:, ['date','locale_name','on_hol','on_evt']]\n",
    "       .rename(columns={'locale_name':'city'})\n",
    ")\n",
    "locR = (\n",
    "    hol.query(\"locale=='Regional'\")\n",
    "       .loc[:, ['date','locale_name','on_hol','on_evt']]\n",
    "       .rename(columns={'locale_name':'state'})\n",
    ")\n",
    "locN = hol.query(\"locale=='National'\")[['date','on_hol','on_evt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOlOBQN8bfbg"
   },
   "outputs": [],
   "source": [
    "# 3. Merge into single DataFrame -----------------------------------------\n",
    "df = (\n",
    "    train\n",
    "      .merge(stores, on='store_nbr', how='left')\n",
    "      .merge(items,  on='item_nbr',  how='left')\n",
    "      .merge(locL,   on=['date','city'],  how='left')\n",
    "      .merge(locR,   on=['date','state'], how='left')\n",
    "      .merge(locN,   on='date',           how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsw8oyd8bhi1"
   },
   "outputs": [],
   "source": [
    "# 4. Keep only final features --------------------------------------------\n",
    "df = df[[\n",
    "    'id','unit_sales','date','store_nbr','item_nbr',\n",
    "    'city','state','type','cluster','family','class','perishable',\n",
    "    'onpromotion','on_hol','on_evt'\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNtgJhd0bjV1"
   },
   "outputs": [],
   "source": [
    "# 5. Basic transformations -----------------------------------------------\n",
    "#  unit_sales: clip returns to 0,\n",
    "df['unit_sales'] = df['unit_sales'].clip(lower=0)\n",
    "#df['unit_sales'] = np.log1p(df['unit_sales'])\n",
    "\n",
    "#  calendar features\n",
    "df['month']       = df['date'].dt.month\n",
    "df['wage']        = df['date'].dt.day.isin([15, 31]).astype(int)\n",
    "df['is_weekend']  = (df['date'].dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "#  promotions & perishability\n",
    "df['onpromotion'] = df['onpromotion'].map({'False': 0, 'True': 1}).fillna(2).astype(int)\n",
    "df['perishable']  = df['perishable'].map({0: 1.0, 1: 1.25}).fillna(2)\n",
    "\n",
    "#  holiday/event flags\n",
    "# prefer map+fillna so the result is a pandas Series\n",
    "df['on_hol'] = df['on_hol'].map({'Holiday': 1}).fillna(-1).astype(int)\n",
    "df['on_evt'] = df['on_evt'].map({'Event':   1}).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206297,
     "status": "ok",
     "timestamp": 1755445403930,
     "user": {
      "displayName": "Asutosh Samal",
      "userId": "01434217950508731589"
     },
     "user_tz": -60
    },
    "id": "y2FWMf8vblTM",
    "outputId": "b858417d-a15e-41ab-a116-51d924ac57e5"
   },
   "outputs": [],
   "source": [
    "# 6. Outlier detection & replacement (IQR fence rule) -------------------\n",
    "\n",
    "# Compute Q1, Q3, IQR and upper bound per item\n",
    "Q1 = df.groupby('item_nbr')['unit_sales'].quantile(0.25)\n",
    "Q3 = df.groupby('item_nbr')['unit_sales'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Summarize outlier rate per item\n",
    "def detect_outlier_rate(group, ub):\n",
    "    n = len(group)\n",
    "    return (group['unit_sales'] > ub[group.name]).sum() / max(n, 1)\n",
    "\n",
    "outlier_rate = df.groupby('item_nbr').apply(lambda g: detect_outlier_rate(g, upper_bound))\n",
    "outlier_rate.name = 'outlier_rate'\n",
    "\n",
    "# Compute non-outlier mean per item\n",
    "non_outlier_mean = (\n",
    "    df.groupby('item_nbr')['unit_sales']\n",
    "      .apply(lambda x: x[x <= upper_bound[x.name]].mean())\n",
    ")\n",
    "non_outlier_mean.name = 'non_outlier_mean'\n",
    "\n",
    "# Merge stats back into df\n",
    "df = df.merge(Q1.rename('Q1'),           on='item_nbr')\n",
    "df = df.merge(Q3.rename('Q3'),           on='item_nbr')\n",
    "df = df.merge(upper_bound.rename('upper_bound'), on='item_nbr')\n",
    "df = df.merge(outlier_rate.reset_index(),       on='item_nbr')\n",
    "df = df.merge(non_outlier_mean.reset_index(),   on='item_nbr')\n",
    "\n",
    "# Replace outliers for items with >10% outlier rate\n",
    "mask = (df['outlier_rate'] > 0.10) & (df['unit_sales'] > df['upper_bound'])\n",
    "df.loc[mask, 'unit_sales'] = df.loc[mask, 'non_outlier_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVaelwV-CZa2"
   },
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Create 'day' column with weekday names\n",
    "df['day'] = df['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B997UZPhboII"
   },
   "outputs": [],
   "source": [
    "# 7. Target (mean/rank) encode categoricals\n",
    "\n",
    "categorical_cols = [\n",
    "    'store_nbr','item_nbr','city','state',\n",
    "    'type','cluster','family','class', 'day'\n",
    "]\n",
    "for col in categorical_cols:\n",
    "    mean_sales = df.groupby(col)['unit_sales'].mean().sort_values()\n",
    "    rank_map   = {cat: rank+1 for rank, cat in enumerate(mean_sales.index)}\n",
    "    df[col + '_rank'] = df[col].map(rank_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeQtH-Qhp---"
   },
   "outputs": [],
   "source": [
    "# 4. Keep only final features --------------------------------------------\n",
    "df1 = df[[\n",
    "    'id','unit_sales','date','day','store_nbr','item_nbr',\n",
    "    'city','state','type','cluster','family','class','perishable',\n",
    "    'onpromotion','on_hol','on_evt'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAkyg4Tyn3Si"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute correlation matrix (as before)\n",
    "corr = df1.select_dtypes(include=['number']).drop(columns=['id']).corr()\n",
    "\n",
    "# Plot with annotations\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,      # show numbers\n",
    "    fmt='.2f',       # two decimal places\n",
    "    cmap='coolwarm',\n",
    "    square=True,\n",
    "    cbar=True,\n",
    "    linewidths=0.5   # grid lines between cells\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0qRMrp7qnjK"
   },
   "outputs": [],
   "source": [
    "# Create df_final with only the required features (dropping raw categoricals & outlier stats)\n",
    "df_final = df[[\n",
    "    'id',\n",
    "    'unit_sales',\n",
    "    'date',\n",
    "    'perishable',\n",
    "    'onpromotion',\n",
    "    'on_hol',\n",
    "    'on_evt',\n",
    "    'month',\n",
    "    'wage',\n",
    "    'is_weekend',\n",
    "    'day_rank',\n",
    "    'store_nbr_rank',\n",
    "    'item_nbr_rank',\n",
    "    'city_rank',\n",
    "    'state_rank',\n",
    "    'type_rank',\n",
    "    'cluster_rank',\n",
    "    'family_rank',\n",
    "    'class_rank'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CoKKlWjENct"
   },
   "outputs": [],
   "source": [
    "# Drop '_rank' suffix from rank columns for clarity\n",
    "df_final.columns = [col.replace('_rank', '') if col.endswith('_rank') else col for col in df_final.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "executionInfo": {
     "elapsed": 2927,
     "status": "ok",
     "timestamp": 1755450676691,
     "user": {
      "displayName": "Asutosh Samal",
      "userId": "01434217950508731589"
     },
     "user_tz": -60
    },
    "id": "dZSHPyvaA2Rk",
    "outputId": "f6d5024a-6aac-4c14-d3c7-ccdac9d7e41f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit_sales</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perishable</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onpromotion</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on_hol</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on_evt</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wage</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>124217119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "id             124217119\n",
       "unit_sales     124217119\n",
       "date           124217119\n",
       "perishable     124217119\n",
       "onpromotion    124217119\n",
       "on_hol         124217119\n",
       "on_evt         124217119\n",
       "month          124217119\n",
       "wage           124217119\n",
       "is_weekend     124217119\n",
       "day            124217119\n",
       "store_nbr      124217119\n",
       "item_nbr       124217119\n",
       "city           124217119\n",
       "state          124217119\n",
       "type           124217119\n",
       "cluster        124217119\n",
       "family         124217119\n",
       "class          124217119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4FAzZg7HnP7"
   },
   "outputs": [],
   "source": [
    "output_path = '/content/drive/MyDrive/Dissertation/df_train.csv'\n",
    "df_final.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1753742752922,
     "user": {
      "displayName": "Asutosh Samal",
      "userId": "01434217950508731589"
     },
     "user_tz": -60
    },
    "id": "44MwWSbwLMX9",
    "outputId": "6ed06f4e-ab3a-44ca-e8f2-92fff56eef76"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Compute absolute correlations to unit_sales\n",
    "#corr = df_final.select_dtypes(include=['number']).drop(columns=['id']).corr()\n",
    "corr_to_target = corr['unit_sales'].abs().drop('unit_sales')\n",
    "sorted_corr = corr_to_target.sort_values()\n",
    "\n",
    "# 2) Identify bottom 5%\n",
    "n_feats   = len(sorted_corr)\n",
    "n_remove  = max(1, int(np.floor(n_feats * 0.05)))\n",
    "worst_feats = sorted_corr.index[:n_remove]\n",
    "\n",
    "# 3) Plot horizontal bar chart\n",
    "plt.figure(figsize=(8, max(6, n_feats*0.2)))\n",
    "bars = plt.barh(sorted_corr.index, sorted_corr.values)\n",
    "\n",
    "# Hatch the worst 5%\n",
    "for i, feat in enumerate(sorted_corr.index):\n",
    "    if feat in worst_feats:\n",
    "        bars[i].set_hatch('//')\n",
    "\n",
    "plt.xlabel('Absolute correlation with unit_sales')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Correlations with unit_sales  (bottom 5% hatched)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Bottom 5% to drop ({n_remove} features): {list(worst_feats)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34910,
     "status": "ok",
     "timestamp": 1755445999965,
     "user": {
      "displayName": "Asutosh Samal",
      "userId": "01434217950508731589"
     },
     "user_tz": -60
    },
    "id": "YzQQgBRvM8vU",
    "outputId": "7d4682e4-2e54-4dbf-d682-ce0be7896198"
   },
   "outputs": [],
   "source": [
    "#  Apply log1p transformation to target\n",
    "df_final[\"unit_sales\"] = df_final[\"unit_sales\"].clip(lower=0)  # Ensure no negative values\n",
    "\n",
    "#  Train-test split based on year\n",
    "train_df = df_final[df_final['date'].dt.year < 2017]\n",
    "test_df  = df_final[df_final['date'].dt.year == 2017]\n",
    "\n",
    "# Drop 'date' and 'year' from features\n",
    "X_train = train_df.drop(columns=[\"unit_sales\", \"date\", \"wage\",\"on_evt\"])\n",
    "y_train = train_df[\"unit_sales\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"unit_sales\", \"date\", \"wage\",\"on_evt\"])\n",
    "y_test = test_df[\"unit_sales\"]\n",
    "\n",
    "X_train_pgrs = train_df.drop(columns=[\"date\", \"wage\",\"on_evt\"])\n",
    "X_test_pgrs = test_df.drop(columns=[\"date\", \"wage\",\"on_evt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1R8YWkF1sw3"
   },
   "outputs": [],
   "source": [
    "# Output path\n",
    "output_path = '/content/drive/MyDrive/Dissertation/final/'\n",
    "\n",
    "# Create and save DataFrames\n",
    "df_20 = X_train_pgrs.iloc[:20_000_000]\n",
    "df_20.to_csv(f\"{output_path}df_20.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRoZHREw20Cc"
   },
   "outputs": [],
   "source": [
    "output_path = '/content/drive/MyDrive/Dissertation/final/'\n",
    "\n",
    "df_40 = X_train_pgrs.iloc[:40_000_000]\n",
    "df_40.to_csv(f\"{output_path}df_40.csv\", index=False)\n",
    "\n",
    "df_60 = X_train_pgrs.iloc[:60_000_000]\n",
    "df_60.to_csv(f\"{output_path}df_60.csv\", index=False)\n",
    "\n",
    "df_80 = X_train_pgrs.iloc[:80_000_000]\n",
    "df_80.to_csv(f\"{output_path}df_80.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJt8WAajPj9t"
   },
   "outputs": [],
   "source": [
    "output_path = '/content/drive/MyDrive/Dissertation/final/df_train.csv'\n",
    "X_train_pgrs.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHUjS2CgPvAR"
   },
   "outputs": [],
   "source": [
    "output_path = '/content/drive/MyDrive/Dissertation/final/df_test.csv'\n",
    "X_test_pgrs.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyNOzVBGLbWbLRxVfMoX7pPD",
   "gpuType": "V28",
   "mount_file_id": "1XtBqkBWB4TC6rhPdDwzAM2riGOAV1vh8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
